"""
å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚„è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å‹ï¼ˆfloat32ç­‰ï¼‰ã®æ•´ç†ã€æ¬ æå€¤ã®æœ€å°é™ã®å‡¦ç†ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®ç®—å‡ºã‚’è¡Œã„ã€
ã€Œãƒ‰ãƒ¡ã‚¤ãƒ³ã«ä¾å­˜ã—ãªã„ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ»ãƒ‡ãƒ¼ã‚¿ã€ã¨ã—ã¦ä¿å­˜
"""
import os
import pandas as pd
from pathlib import Path
import glob
import gc
from src.data_loader.loader import DataLoader
from src.features.engineer import FeatureEngineer
import warnings
from tqdm import tqdm
# pandas_taç­‰ã®è­¦å‘ŠæŠ‘åˆ¶
warnings.filterwarnings("ignore")

# ==========================================
# è¨­å®š (Configuration)
# ==========================================
PROJECT_DIR = Path(__file__).resolve().parents[2]
TEMP_DIR = PROJECT_DIR / 'data/temp_scode'
OUTPUT_PATH = PROJECT_DIR / 'data/intermediate/date_chunks'
BATCH_SIZE = 50  # éŠ˜æŸ„ãƒãƒƒãƒå‡¦ç†ã‚µã‚¤ã‚º (ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ã«å¿œã˜ã¦èª¿æ•´)

def standardize_raw_data():
    os.makedirs(TEMP_DIR, exist_ok=True)
    os.makedirs(OUTPUT_PATH, exist_ok=True)

    loader = DataLoader()
    engineer = FeatureEngineer()
    all_symbols = loader.get_all_symbols()
    df_topix = loader.fetch_topix_data()
    df_n225 = loader.fetch_n225_data()
    df_fins = loader.fetch_financial()
    df_investor_types = loader.fetch_investor_types()
    df_margin_weekly = loader.fetch_margin_weekly()
    # ä¿¡ç”¨æ®‹é«˜ã¯é€šå¸¸ã€Œé‡‘æ›œç· ã‚ã€â†’ã€Œç¿Œé€±ç«æ›œå…¬è¡¨ã€
    # ãã®ãŸã‚ã€marginãƒ‡ãƒ¼ã‚¿ã®Dateã« +4æ—¥ (ç«æ›œæ—¥) åŠ ç®—ã—ã¦ã‹ã‚‰çµåˆã™ã‚‹
    df_margin = df_margin_weekly.copy()
    df_margin['available_date'] = pd.to_datetime(df_margin['date']) + pd.Timedelta(days=4)
    df_shrt_sector = loader.fetch_short_selling_sector()

    # --- A. éŠ˜æŸ„åˆ¥ãƒ«ãƒ¼ãƒ— (æ™‚ç³»åˆ—è¨ˆç®—) ---
    for i in tqdm(range(0, all_symbols.shape[0], BATCH_SIZE), desc="Processing Batches"):
        batch_symbols = list(all_symbols.iloc[i : i + BATCH_SIZE,0]) # scode_list
        df_batch = loader.fetch_batch_data(batch_symbols) # éŠ˜æŸ„åˆ¥OHLCVãƒ‡ãƒ¼ã‚¿
        if df_batch.empty:
            continue
        df_batch = pd.merge(df_batch, all_symbols, on='scode', how='left')
        df_batch = pd.merge(df_batch, df_topix, on='date', how='left', suffixes=('', '_mkt'))
        df_batch = pd.merge(df_batch, df_n225, on='date', how='left')
        df_batch = pd.merge(df_batch, df_investor_types, on='date', how='left')
        df_batch['date'] = pd.to_datetime(df_batch['date'])
        df_batch = df_batch.sort_values('date')
        # è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã®çµåˆ
        batch_fins = df_fins[df_fins['scode'].isin(batch_symbols)].sort_values(['published_date'])
        df_batch = pd.merge_asof(
            df_batch,
            batch_fins,
            left_on='date',
            right_on='published_date',
            by='scode',
            direction='backward'
        )
        # ä¿¡ç”¨å–å¼•ãƒ‡ãƒ¼ã‚¿ã®çµåˆ
        batch_margin = df_margin[df_margin['scode'].isin(batch_symbols)].sort_values('available_date')
        df_batch = pd.merge_asof(
            df_batch,
            batch_margin[['scode', 'available_date', 'long_margin_trade_balance_share', 'short_margin_trade_balance_share']],
            left_on='date',
            right_on='available_date',
            by='scode',
            direction='backward'
        )
        # æ¥­ç¨®åˆ¥ç©ºå£²ã‚Šæ¯”ç‡ãƒ‡ãƒ¼ã‚¿ã®çµåˆ
        batch_shrt_sector = df_shrt_sector[df_shrt_sector['sector33_code'].isin(df_batch['sector33_code'].unique())].sort_values('date')
        df_batch = pd.merge_asof(
            df_batch,
            batch_shrt_sector,
            left_on='date',
            right_on='date',
            by='sector33_code',
            direction='backward'
        )
        for symbol, df_stock in df_batch.groupby('scode'):
            df_stock = df_stock.sort_values('date').reset_index(drop=True)
            df_feat = engineer.add_time_series_features(
                df_stock, 
                output_target=True
            )
            if df_feat.empty: continue
            # éå»ãƒ‡ãƒ¼ã‚¿ã®é™¤å¤–ã€momentum_12_1åŸºæº–ã§
            df_feat = df_feat.dropna(subset='momentum_12_1')
            # ä¸Šå ´é–“ã‚‚ç„¡ã„éŠ˜æŸ„ã‚’é™¤å¤–ã€Dist_SMA75åŸºæº–ã§
            df_feat = df_feat.dropna(subset='Dist_SMA75')
            # ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã®é™¤å¤–ã€Future_X_StråŸºæº–ã§
            df_feat = df_feat.dropna(subset='Future_High_Str')
            # æœ€ä½é™ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€€å¹³å‡å£²è²·ä»£é‡‘ãŒ5åƒä¸‡æœªæº€ã‚’é™¤å¤–
            if df_feat['volume_p_MA5'].mean() < 50_000_000:
                continue
            # ä¸€æ™‚ä¿å­˜
            df_feat.to_parquet(f"{TEMP_DIR}/{symbol}.parquet")

    del df_topix, df_fins, df_investor_types, df_margin_weekly, df_margin, df_shrt_sector
    gc.collect()

    # --- B. æ—¥ä»˜åˆ¥ãƒ«ãƒ¼ãƒ— (ãƒãƒ£ãƒ³ã‚¯åŒ–) ---
    # å…¨éŠ˜æŸ„ã®ã€ŒMA_250è¨ˆç®—æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã€ã‚’æ—¥ä»˜ã§ã¾ã¨ã‚ã¦ä¿å­˜ã—ç›´ã™
    print("Regrouping data into date chunks...")
    all_temp_files = glob.glob(f"{TEMP_DIR}/*.parquet")
    # 8GBãƒ¡ãƒ¢ãƒªã®ãŸã‚ã€å…¨èª­ã¿è¾¼ã¿ã›ãšã€Œæœˆå˜ä½ã€ã§é›†è¨ˆ
    # ã“ã“ã§ã¯ä¾‹ã¨ã—ã¦2016å¹´ã‹ã‚‰2025å¹´ã¾ã§ã‚’ãƒ«ãƒ¼ãƒ—
    dates = pd.date_range(start="2016-10-01", end="2025-12-31", freq='QS') # å››åŠæœŸã”ã¨
    for start_date in dates:
        end_date = start_date + pd.DateOffset(months=3)
        chunk_list = []
        for f in all_temp_files:
            stock_chunk = pd.read_parquet(f)
            # æœŸé–“å†…ã®ã¿æŠ½å‡º
            mask = (stock_chunk['date'] >= start_date) & (stock_chunk['date'] < end_date)
            if mask.any():
                chunk_list.append(stock_chunk[mask])
        if chunk_list:
            final_chunk = pd.concat(chunk_list)
            chunk_name = f"standardized_{start_date.strftime('%Y%m')}.parquet"
            final_chunk.to_parquet(f"{OUTPUT_PATH}/{chunk_name}")
            print(f"âœ… Created chunk: {chunk_name}")
        del chunk_list
        gc.collect()

    print("ğŸ‰ All raw data standardized and chunked.")

if __name__ == "__main__":
    standardize_raw_data()